整体模型改成多进程 除了“看门狗”（需要fork的进程） 其余进程都可以是多线程的
进程之间通讯只用TCP

造几个轮子：
  !!线程池重构
  !!封装poll 模型:per_thread_one_loop
  !!封装socket  默认都用TCP
  !!一个高效的日志系统
  !!封装mutex & condition



版本0.1.0
 重新设计服务端：
 1.mysql+redis代替文件存储与内存缓冲
 2.LRU通过redis的策略实现，不再使用之前的热数据判断方法
 3.修改数据格式
 4.实现线程池
 5.添加demo


#=====================版本：0.0.1========================
#安装方法
#    初次安装 运行install.sh
#    将会编译安装客户端和服务端 并默认创建1000个测试文件 测试文件存放在books路径下 每个文件都是.json文件
#    创建出的书（测试文件）以id命名 全部书的id放在booklist文件中
#卸载
#    运行clean.sh
#重新生成测试文件
#    运行create_file.sh文件 需要两个参数  ：文件数量 存放文件的目录数量
#    create_file.sh必须在运行install.sh之后才可以执行成功
#
#运行服务器
#    服务器程序为ser 运行时要一个参数 ：绑定的端口号 如: ./ser 8888
#
#运行客户端
#    客户端程序为cli 运行时要两个参数 ： 服务器ip 端口号 如：/cli 0 8888
#
#代码思路：
#    本题目主要有两个问题：1.服务器中有大量图书信息的文件 2.服务器的访问量高
#    对于问题1：
#        将图书信息根据id  hash到不同的文件夹中 例如本题中的200 0000个文件 可以hash到1000个文件夹中
#        这样每个文件夹中就只有2000个文件 加快查找速度
#    对于问题2:
#        服务器的访问量表现在两个方面:每秒的请求数量2000个 对20%的文件高频率访问
#        针对请求数量：
#                      epoll+线程池 主线程负责监听 每当有新的连接到来 创建一个临时线程处理连接 将新的连接放入epoll中
#                      首先维护一个就绪队列  根据cpu数量创建相应个数的线程 这些线程当做线程池  每当有文件描述符可读
#                      将可读文件描述符(不是请求连接的描述符)放入就绪队列 空闲线程到就绪队列中拿一个文件描述符出来处理
#                      实际上是一种生产者消费者模型
#        针对高频率文件的问题:
#                      使用一个map作为数据缓冲 每次打开的文件以mmap的形式映射到内存 不立即释放 托管到map map以书的id为key
#                      每当map中的数据过多的时候 以本题为例 当map中文件大于20 0000时 对数据缓存中的数据进行一次释放 
#                      每次释放30%的冷数据  
#                      实现了对冷热数据的简单判断 根据文件的访问次数 平均访问时间间隔 最后一次访问时间 选出相应的热数据与冷数据
#                      由于缓冲会间隔性的释放一部分冷数据 所以可以尽量只缓冲当前的热数据
#
#
